def train(dataloader, model, loss_fn, optimizer, device, alpha=0.5):
    size = len(dataloader.dataset)
    model.train()
    for batch, b_sample in enumerate(tqdm(dataloader)):
        source_id, target_id, x, seq_input, seq_input_score = (
            b_sample['source_id'].to(device), b_sample['target_id'].to(device),
            b_sample['x'].to(device), b_sample['seq_data'][:, :100].to(device),
            b_sample['seq_data'][:, 100:].to(device))
        y = b_sample['y'].to(device)

        # Compute prediction error
        pred, usr_att, item_att = model(source_id, target_id,
                                        x, seq_input,
                                        seq_input_score)
        loss1 = loss_fn(pred, y)
        # 计算KL散度
        loss2 = kl_divergence(usr_att, item_att)

        loss_all = alpha * loss1 + (1 - alpha) * loss2

        # Backpropagation
        optimizer.zero_grad()
        loss_all.backward()
        optimizer.step()

        # if batch % 50 == 0:
        #     loss_all, current = loss_all.item(), (batch + 1) * len(source_id)
        #     print(f"loss: {loss_all:>7f}  [{current:>5d}/{size:>5d}]")


def test(dataloader, model, loss_fn, device, alpha=0.5, name='train'):
    model.eval()
    test_loss, correct, samples = 0, 0, 0
    with torch.no_grad():
        for b_sample in tqdm(dataloader):
            source_id, target_id, x, seq_input, seq_input_score = (
                b_sample['source_id'].to(device),
                b_sample['target_id'].to(device), b_sample['x'].to(device),
                b_sample['seq_data'][:, :100].to(device),
                b_sample['seq_data'][:, 100:].to(device))

            y = b_sample['y'].to(device)

            pred, usr_att, item_att = model(source_id, target_id, x, seq_input,
                                            seq_input_score)

            loss1 = loss_fn(pred, y)

            # 计算KL散度
            loss2 = kl_divergence(usr_att, item_att)

            loss_all = alpha * loss1 + (1 - alpha) * loss2
            test_loss += loss_all.item()
            correct += (pred.argmax(1) == y).type(torch.float).sum().item()

            samples += y.shape[0]

    test_loss /= len(dataloader)
    correct /= samples
    print(
        f"{name} Error: \n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \n"
    )
    return test_loss, correct
